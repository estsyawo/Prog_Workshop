cj=function(x) (x^-2 + (1-x)^-2)
curve(cj,0,1)
cj=function(x) (x^-2 + (1-x)^-2)^-.5
curve(cj,0,1)
rk
curve(rk,-2,1)
curve(cj,0,1)
ck=function(x) (x^.5 + (1-x)^.5)^2
curve(ck,0,1)
curve(cj,0,1)
fx = function(y) 1-(y^2/4)
curve(fx,0,2)
curve(fx,-2,2)
curve(fx,-8,8)
curve(fx,-3,3)
ff<- function(t) 1/t
curve(ff,2,1000)
Q=function(p) exp(2*log(p))
P=function(p) exp(2*log(Q))
curve(P,1,4)
P=function(Q) exp(2*log(Q))
curve(P,1,4)
P=function(Q) exp(-2*log(Q))
curve(P,1,4)
fg<- function(x) (x*exp(-x))/(1+exp(-x))^2
fg(0)
integrate(fg,-Inf,Inf)
curve(fg,-10,10)
uniroot(function(x) 49/x - x, -1,10)
uniroot(function(x) 49/x - x, c(-1,10))
fn= function(q) (49/q) - q
curve(fn,-1,10)
abline(h=0)
uniroot(function(x) 49/x - x, 0,10)
uniroot(function(x) 49/x - x, c(0,10))
Y= rnor
expand.grid(height = seq(60, 80, 5), weight = seq(100, 300, 50),
sex = c("Male","Female"))
combin(1000,2)
View(combin)
combin(100,10)
f = function(x) combin(100,x)
f=Vectorize(f)
fv=f(1:10)
plot(1:10,fv)
plot(1:100,fv,type = "l")
xx=1:100
fv=f(xx)
plot(xx,fv,type = "l")
max(fv)
min(fv)
f(20)
765.63/6
library(bayesdistreg)
?bayesdistreg
839+3379
186.42+163.00
install.packages("pryr")
pryr::show_c_source(.Internal(mean(x)))
View(lm)
View(lm.fit)
install.packages("gls")
install.packages("gsl")
?gsl
library(gsl)
View(gsl::bessel_I0)
?.C
devtools::install_github('cjgeyer/mat')
devtools::install_github("cjgeyer/mat")
install.packages("baz")
factorial(6)
View(solve)
set.seed(12); X = round(rnorm(10),2)
X
set.seed(14); Y = cbind(1,X)%*%c(1.0,-1.0) + round(rnorm(10,sd=0.1))
Y
lm(Y~X)
paste(cbind(1,X),collapse = "+")
paste(cbind(1,X),collapse = ",")
paste(Y,collapse = ",")
18+31+21.57
(18+31+21.57)/3
ceiling((18+31+21.57)/3)
0.75*15
n <- 9
k <- 3
l <- 3
n <- 9
k <- 3
l <- 3
X <- matrix(1:n, k)
Y <- matrix(1:n, l)
set.seed(2); aX = matrix(runif(n), k)
aX
aX = matrix(runif(n), k); aY = matrix(rnorm(n), k)
XtX <- t(X) %*% X
XtX
(XtX <- t(X) %*% X)
(aXtX<- t(aX) %*% aX)
round(aXtX<- t(aX) %*% aX,2)
XX <-matrix(0:0,ncol(X),ncol(X))
for(i in 1:ncol(X)){
for(j in 1:i){
for (k in 1:nrow(X)){
XX[i,j]<-XX[i,j]+X[k,i]*X[k,j]
}
if(i!=j){
XX[j,i]=XX[i,j]}
}
}
XX
all.equal(XX,XtX)
fx = function(X){for(i in 1:ncol(X)){
XX <-matrix(0:0,ncol(X),ncol(X))
for(j in 1:i){
for (k in 1:nrow(X)){
XX[i,j]<-XX[i,j]+X[k,i]*X[k,j]
}
if(i!=j){
XX[j,i]=XX[i,j]}
}
}
return(XX)
}
all.equal(fx(X),XtX)
X <- matrix(1:n, k)
fx = function(X){
XX <-matrix(0:0,ncol(X),ncol(X))
for(i in 1:ncol(X)){
for(j in 1:i){
for (k in 1:nrow(X)){
XX[i,j]<-XX[i,j]+X[k,i]*X[k,j]
}
if(i!=j){
XX[j,i]=XX[i,j]}
}
}
return(XX)
}
all.equal(fx(X),XtX)
all.equal(fx(aX),aXtX)
fx2 <- function(X,Y){
XY <-matrix(0:0,ncol(X),ncol(Y))
for(i in 1:ncol(X)){
for(j in 1:nrow(X)){
for (k in 1:nrow(Y)){
XY[i,j]<-XY[i,j]+X[k,i]*Y[k,j]
}
}
}
return(XY)
}
all.equal(fx2(X,Y),XtY)
XtY <- t(X) %*% Y
XtY
fx2 <- function(X,Y){
XY <-matrix(0:0,ncol(X),ncol(Y))
for(i in 1:ncol(X)){
for(j in 1:nrow(X)){
for (k in 1:nrow(Y)){
XY[i,j]<-XY[i,j]+X[k,i]*Y[k,j]
}
}
}
return(XY)
}
all.equal(fx2(X,Y),XtY)
(aXtY <- t(aX) %*% aY)
fx2 <- function(X,Y){
XY <-matrix(0:0,ncol(X),ncol(Y))
for(i in 1:ncol(X)){
for(j in 1:nrow(X)){
for (k in 1:nrow(Y)){
XY[i,j]<-XY[i,j]+X[k,i]*Y[k,j]
}
}
}
return(XY)
}
all.equal(fx2(X,Y),XtY)
all.equal(fx(aX, aY),aXtY)
all.equal(fx2(aX, aY),aXtY)
(XYt <- X %*% t(Y))
(aXYt <- aX %*% t(aY))
fx3 <- function(X,Y){
XY2 <-matrix(0:0,ncol(X),ncol(Y))
for(i in 1:ncol(X)){
for(j in 1:nrow(X)){
for (k in 1:nrow(Y)){
XY2[i,j]<-XY2[i,j]+X[i,k]*Y[j,k]
}
}
}
return(XY2)
}
all.equal(fx3(X,Y),XYt)
all.equal(fx3(aX, aY),aXYt)
n <- 9
k <- 3
l <- 3
X <- matrix(1:n, k)
Y <- matrix(1:n, l)
set.seed(2);
aX = matrix(runif(n), k); aY = matrix(rnorm(n), k)
(XtX <- t(X) %*% X)
round(aXtX<- t(aX) %*% aX,2)
fxtx = function(X){
XX <-matrix(0:0,ncol(X),ncol(X))
for(i in 1:ncol(X)){
for(j in 1:i){
for (k in 1:nrow(X)){
XX[i,j]<-XX[i,j]+X[k,i]*X[k,j]
}
if(i!=j){
XX[j,i]=XX[i,j]}
}
}
return(XX)
}
all.equal(fxtx(X),XtX)
all.equal(fxtx(aX),aXtX)
fxyt <- function(X,Y){
XY2 <-matrix(0:0,ncol(X),ncol(Y))
for(i in 1:ncol(X)){
for(j in 1:nrow(X)){
for (k in 1:nrow(Y)){
XY2[i,j]<-XY2[i,j]+X[i,k]*Y[j,k]
}
}
}
return(XY2)
}
all.equal(fxyt(X,Y),XYt)
all.equal(fxyt(aX, aY),aXYt)
(XYt <- X %*% t(Y))
(aXYt <- aX %*% t(aY))
all.equal(fxyt(X,Y),XYt)
all.equal(fxyt(aX, aY),aXYt)
9/5
sort(sample(1:29,5))
rootSolve::uniroot.all(function(x) x-cos(x),c(-pi,pi))
curve(function(x)x-cos(x),-pi,pi)
curve(function(x){x-cos(x)},-pi,pi)
sort(sample(1:24,3))
sort(sample(1:29,4))
sort(sample(1:29,2))
sort(sample(1:47,5))
library("AER")
library("MASS") # this package is in-built. you don't need to install it
rd_nb <- glm.nb(trips ~ ., data = RecreationDemand)
summary(rd_nb)
data("RecreationDemand") # load data from AER package
rd_pois <- glm(trips ~ ., data = RecreationDemand,
family = poisson)
summary(rd_pois)
library("MASS") # this package is in-built. you don't need to install it
rd_nb <- glm.nb(trips ~ ., data = RecreationDemand)
summary(rd_nb)
rbind(rd_pois$coefficients,rd_nb$coefficients)
require("quantreg") # the command require() is synonymous to library()
?rq
data(stackloss)
rq(stack.loss ~ stack.x,tau=.5)  # LAD is a special case of quantreg
rq(stack.loss ~ stack.x,tau=.25)
data("Journals")
journals <- Journals[, c("subs", "price")]
journals$citeprice <- Journals$price/Journals$citations
jour_lm <- lm(log(subs) ~ log(citeprice), data = journals)
refit <- function(data, i) coef(lm(log(subs) ~ log(citeprice), data = data[i,]))
library("boot") #load package for bootstapping
set.seed(123) # set seed for reproducibility
jour_boot <- boot(journals, refit, R = 999)
coeftest(jour_lm)
boot.ci(jour_boot, index = 2, type = "basic") # compute confidence intervals
coeftest(jour_lm)
confint(jour_lm, parm = 2)
library(rootSolve)
install.packages(rootSolve)
install.packages("rootSolve")
library("numDeriv")
install.packages("numDeriv")
library("pracma")
install.packages("pracma")
library("R2Cuba")
install.packages("R2Cuba")
install.packages("alabama")
options(digits=3)
set.seed(3)
A = matrix(runif(16), nrow = 4)
A
set.seed(3)
B = runif(4)
B
solve(A,B) #solve for the unkowns x in Ax=B
A%*%solve(A,B) # Should recover b
polyroot(c(1, 2i, 3-7i)) # R recognises undefined i as complex polynomial
rt=polyroot(c(0, -6, -7, 0, 1))
f = function(x) -6*x - 7*x^2 + x^4
f(0); f(-1); f(2)
curve(f,from = -5, to=5)
abline(h=0)
round(f(rt),2)
f = function(x,a) x^(1/3)*sin(5*x) - a*x^(1/2)
curve(f(x,a=0.5),0,5)
abline(h=0, lty=3) # this curve has several zeros
require(rootSolve) #load rootSolve package.
zpts=uniroot.all(f,c(0,5),a=0.5)
zpts
yz=rep(0,length(zpts))
points(zpts,yz) # Locate roots on graph of function
set.seed(13)
A = matrix(rnorm(30), nrow=6)
svd(A)
options(digits=3)
M = matrix(c(2,-1,0,-1,2,-1,0,-1,2), nrow=3, byrow=TRUE)
eigen(M)
options(digits=3)
set.seed(1)
require(Matrix)
mm = Matrix(round(rnorm(9),2), nrow = 3)
mm
lum = lu(mm) #take the LU decomposition and save as object lum
str(lum) #view its structure
elu = expand(lum) #expand to view elements of object lum
elu
chol(M)
sum(diag(M))
fs = function(s) s^3 - 3*s^2 +4*rho
rho=0.96
curve(fs(x),0,3); abline(h=0)
options(digits=3)
multiroot(fs, c(1.5,2.5))
require(rootSolve)
model = function(x) c(F1 = 10*x[1]+3*x[2]^2-3,
F2 = x[1]^2 -exp(x[2]) -2)
(ss = multiroot(model,c(1,1)))
f = function(x) x^3 * sin(x/3) * log(sqrt(x))
df = function(f,x0,h) (f(x0+h)-f(x0))/h
x0 = 1; h = 1e-5
df(f,x0,h)
dfb = function(f,x0,h) (f(x0)-f(x0-h))/h
dfb(f,x0,h)
dfc<- function(f,x0,h) (f(x0+h)-f(x0-h))/(2*h)
dfc(f,x0,h)
require(numDeriv)
options(digits=16)
grad(f, 1, method = "simple")
grad(f, 1, method = "Richardson")
grad(f, 1, method = "complex")
lfun<- function(pars) like(y=dat$nonwife,x=xx,pars)#define as function of pars
grad(lfun,rep(1,4)) # compute the gradient of the likelihood function
getwd()
setwd("~/Dropbox/Prog_Codes/Prog_Workshop/Session_1")
dat<- read.csv("dat.csv",header = T,sep = " ")
like<- function(y,x,pars){
N = length(y) #obtain number of observations
y = matrix(y,ncol = 1) # a matrix of column length 1
x = as.matrix(cbind(1,x)) # include 1's for the intercept term
k=ncol(x) # number of parameters to estimate
np = length(pars) #obtain number of parameters (including sigma)
beta = matrix(pars[-np],ncol = 1) #obtain column vector of parameters
sig = pars[np]
res<- y - x%*%beta
ll = sum(dnorm(res,sd=sqrt(sig),log = T)) #obtain log joint likelihood
return(ll)
}
like(y=dat$nonwife,x=xx,pars = rep(1,4))
xx = as.matrix(cbind(dat$age,dat$experience))
lfun<- function(pars) like(y=dat$nonwife,x=xx,pars)#define as function of pars
grad(lfun,rep(1,4)) # compute the gradient of the likelihood function
f = function(u){
x = u[1]; y = u[2]; z = u[3]
return(2*x + 3*y^2 - sin(z))
}
grad(f,c(1,1,0)) # gradient of f at c(1,1,0)
round(grad(f,c(1,1,0)),3)
require(numDeriv)
F = function(x) c(x[1]^2 + 2*x[2]^2 - 3,
cos(pi*x[1]/2) -5*x[2]^3)
jacobian(F, c(2,1))
options(digits = 5) #set number of digits to display
hessian(f,c(1,1,0))
hessian(lfun,c(rep(1,4))) # compute the gradient of the likelihood function
eigen(hessian(lfun,rep(1,4)))#hessian of the likelihood function at rep(1,4)
require(pracma)
f = function(x) x^3 * sin(x/3) * log(sqrt(x))
x = 1:4
fderiv(f,x) # 1st derivative at 4 points
fderiv(f,x,n=2,h=1e-5) # 2nd derivative at 4 points
f = function(x) exp(-x) * cos(x)
( q = integrate(f, 0, pi) )
f1 = function(x) max(0, x)
integrate(f1, -1, 1)
f1 = function(x) max(0, x)
integrate(f1, -1, 1)
curve(f1,-1,1)
f1=Vectorize(f1)
curve(f1,-1,1)
integrate(f1, -1, 1)
require(pracma)
f = function(x) exp(-x) * cos(x)
xs = seq(0, pi, length.out = 101) # what does the function seq() do?
ys = f(xs)
plot(xs,ys,type = "l")
trapz(xs, ys)
integrate(f,0,pi)
fgauss = function(t) exp(-t^2/2) # specify a function
( q = integrate(fgauss, -Inf, Inf) )
q$value / sqrt(2*pi) # is our approximation accurate?
require(R2Cuba)
N = 10^6
x = runif(N); y = runif(N); z = runif(N)
V = 8 * sum(x^2 + y^2 + z^2 <= 1) / N
V
optimize(function(x) x*(20-2*x)*(16-2*x), c(0,8), maximum=T)
W = function(x) x*(20-2*x)*(16-2*x)
curve(W,0,8)
opt<-optimize(W,c(2,4),maximum = T)
abline(v=opt$maximum)
points(opt$maximum,opt$objective)
opt<-optimize(W,c(2,4),maximum = T)
points(opt$maximum,opt$objective)
curve(W,0,8)
opt<-optimize(W,c(2,4),maximum = T)
points(opt$maximum,opt$objective)
f = function(x) x*sin(4*x)
curve(f,0,3)
optimize(f,c(0,3))
(op<-optimize(f,c(1.5,3)))
abline(v=op$minimum) # a vertical line through the minimum point
f = function(x) x*sin(4*x)
curve(f,0,3)
# Applying optimize() in the simplest way yields
optimize(f,c(0,3))
# Because we have a plot of the function, we can see that we must exclude the
# local minimum from the lower and upper endpoints of the search interval.
(op<-optimize(f,c(1.5,3)))
points(op$minimum,opt$objective) # a vertical line through the minimum point
points(op$minimum,opt$objective)
f = function(x) x*sin(4*x)
curve(f,0,3)
# Applying optimize() in the simplest way yields
optimize(f,c(0,3))
# Because we have a plot of the function, we can see that we must exclude the
# local minimum from the lower and upper endpoints of the search interval.
(op<-optimize(f,c(1.5,3)))
op
points(op$minimum,opt$objective)
abline(v=op$minimum) # a vertical line through the minimum point
optimize(f,c(1,3),maximum=TRUE)
U = function(w) -((w-1000)^2)
curve(U,0,2000)
optimize(U,c(0,2000),maximum = T)
x1 = x2 = seq(.1,.9,.02)
z = outer(x1,x2,FUN=function(x1,x2) 1/x1 + 1/x2 +
(1-x2)/(x2*(1-x1)) + 1/((1-x1)*(1-x2)))
persp(x1,x2,z,theta=45,phi=0)
f = function(x) {
x1 = x[1]
x2 = x[2]
return(1/x1 + 1/x2 + (1-x2)/(x2*(1-x1)) +
1/((1-x1)*(1-x2)))
}
optim(c(.5,.5),f,hessian = T)
optp<-optim(par=c(rep(0,3),2),fn=like,y=dat$nonwife,x=xx,
control=list(fnscale=-1),hessian = T)
optp
lm(dat$nonwife~xx)
summary(lm(dat$nonwife~xx))
f = function(x) sin(x[1]*x[2]+x[3]) # objective function
heq = function(x) -x[1]*x[2]^3 + x[1]^2*x[3]^2 -5 # equality constraint
hin = function(x) { # inequality constraint
h = rep(NA,2)
h[1] = x[1]-x[2] # set as non-negativity constraints
h[2] = x[2] -x[3]
h
}
p0 = c(3,2,1) # starting values for constrained optimisation
require(alabama) # Also loads numDeriv package
(ans = constrOptim.nl(par=p0, fn = f, heq=heq, hin = hin))
p0 = c(1,2,3) # starting values for constrained optimisation
(ans = constrOptim.nl(par=p0, fn = f, heq=heq, hin = hin))
(ans = auglag(par=p0, fn = f, heq=heq, hin = hin))
uF<- function(a) - (a[1]^(-4) + (1.2*a[2])^(-4))^(-0.25) # return fn value for minimisation
p0=c(20,20) # starting values
uF(p0) # function value at starting values
hin<- function(a){
h = rep(NA,3)
h[1]=a[1]-20
h[2]=a[2]-20
h[3]=100-a[1] - a[2]
h
} # non-linear constraints
(opF<- auglag(par = p0,fn=uF,hin = hin))
set.seed(14)
L = rpois(n=300,lambda=8)
K = rbeta(300,2,4)*15
summary(L); summary(K)
a = 0.4; r = 2
Q = 3*(a*K^r + (1-a)*L^r)^(1/r)
summary(Q)
summary(Q)
fnCES = function(pars,Q,L,K){
lF = pars[1]; r = pars[2]; a = pars[3]
sum((log(Q)-log(L)-lF - (1/r)*log(1 + a*((K/L)^r-1)))^2)
}
fnCES(pars = c(1,1,1),Q=Q,L=L,K=K)
ans = optim(par = c(0,1,1),fn=fnCES,Q=Q,L=L,K=K,hessian = TRUE)
F.est=exp(ans$par[1]); r.est=ans$par[2]; a.est = ans$par[3]
rbind(c(F.est,r.est,a.est),3,r,a)
rbind(c(F.est,r.est,a.est),c(3,r,a))
(opF<- auglag(par = p0,fn=uF,hin = hin))
